\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}


\title{\textbf{Numerical Methods\\for Solving Equations}}
\author{Tutoring Centre Ferndale\\\includegraphics[width=4em]{ApS_logo.png}}
\date{}

\begin{document}

\maketitle

Numerical methods are essential tools for solving equations that cannot be solved analytically. These methods provide approximate solutions with a high degree of accuracy and are particularly useful when dealing with transcendental equations like \( 2x = \cos(x) \).

\section*{Bisection Method}

The Bisection Method is a straightforward and reliable method for finding the roots of a continuous function. It requires an initial interval \([a, b]\) where the function changes sign, i.e., \( f(a) \cdot f(b) < 0 \). The method works by repeatedly halving the interval and selecting the subinterval in which the root lies.

\subsection*{Algorithm}
\begin{enumerate}
    \item Calculate the midpoint \( c = \frac{a + b}{2} \).
    \item Evaluate the function at \( c \): \( f(c) \).
    \item Determine the subinterval \([a, c]\) or \([c, b]\) where the root lies, based on the sign of \( f(c) \).
    \item Replace the interval with the subinterval that contains the root.
    \item Repeat the process until the interval is sufficiently small.
\end{enumerate}

The Bisection Method is guaranteed to converge to a root, though it may be slower compared to other methods.

\section*{Newton-Raphson Method}

The Newton-Raphson Method is an iterative technique that uses the derivative of the function to find successively better approximations to the root. It requires an initial guess \( x_0 \) and converges rapidly if the initial guess is close to the actual root.

\subsection*{Formula}
\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\]

\subsection*{Algorithm}
\begin{enumerate}
    \item Start with an initial guess \( x_0 \).
    \item Compute the next approximation using the formula.
    \item Continue iterating until the difference between successive approximations is within a desired tolerance.
\end{enumerate}

The Newton-Raphson Method is fast but requires a good initial guess and a well-behaved derivative.

\section*{Secant Method}

The Secant Method is similar to the Newton-Raphson Method but does not require the computation of derivatives. Instead, it approximates the derivative using two previous points.

\subsection*{Formula}
\[
x_{n+1} = x_n - f(x_n) \cdot \frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}
\]

\subsection*{Algorithm}
\begin{enumerate}
    \item Start with two initial guesses \( x_0 \) and \( x_1 \).
    \item Compute the next approximation using the formula.
    \item Continue iterating until the difference between successive approximations is within a desired tolerance.
\end{enumerate}

The Secant Method is less sensitive to the initial guess than the Newton-Raphson Method.

\section*{Fixed-Point Iteration}

Fixed-Point Iteration involves rewriting the equation in the form \( x = g(x) \) and then iterating \( x_{n+1} = g(x_n) \) until convergence.

\subsection*{Algorithm}
\begin{enumerate}
    \item Express the equation in the form \( x = g(x) \).
    \item Start with an initial guess \( x_0 \).
    \item Compute the next approximation \( x_{n+1} = g(x_n) \).
    \item Continue iterating until the difference between successive approximations is within a desired tolerance.
\end{enumerate}

Fixed-Point Iteration is simple but may converge slowly or not at all if \( g'(x) \) is not properly bounded.

\section*{Regula Falsi (False Position) Method}

The Regula Falsi Method is similar to the Bisection Method but uses a linear interpolation to estimate the root. It maintains the bracketing property of the root while improving convergence.

\subsection*{Formula}
\[
c = b - \frac{f(b)(b - a)}{f(b) - f(a)}
\]

\subsection*{Algorithm}
\begin{enumerate}
    \item Start with an interval \([a, b]\) where the function changes sign.
    \item Calculate the root approximation using the formula.
    \item Determine whether the root lies in \([a, c]\) or \([c, b]\).
    \item Replace the interval with the subinterval that contains the root.
    \item Repeat the process until the interval is sufficiently small.
\end{enumerate}

The Regula Falsi Method often converges faster than the Bisection Method.

\section*{Brent's Method}

Brent's Method is a hybrid technique that combines the Bisection Method, Secant Method, and inverse quadratic interpolation. It is robust and efficient, providing both guaranteed convergence and rapid convergence.

\subsection*{Algorithm}
\begin{enumerate}
    \item Start with an interval \([a, b]\) where the function changes sign.
    \item Use a combination of bisection, secant, and inverse quadratic interpolation to narrow down the interval.
    \item Continue until the root is approximated within a desired tolerance.
\end{enumerate}

Brent's Method is often the method of choice for solving equations numerically because of its reliability and efficiency.

\section*{Conclusion}

Numerical methods are invaluable tools for solving equations that are difficult or impossible to solve analytically. Each method has its strengths and is suitable for different types of problems. The Bisection Method is reliable but slow, while the Newton-Raphson and Secant Methods are faster but require good initial guesses. Brent's Method offers a combination of reliability and speed, making it a preferred choice in many practical applications.

\end{document}
